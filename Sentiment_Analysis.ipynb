{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment Analysis of Multilingual(Tanglish) Movie Reviews"
      ],
      "metadata": {
        "id": "KeZ3o_jnZgEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Tokenizer for word embedding\n",
        "\n"
      ],
      "metadata": {
        "id": "t0I2d0WLf5AT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "data = pd.read_csv('/content/Tamil_sentiments.csv', encoding='utf-8')"
      ],
      "metadata": {
        "id": "FL1YdmQLFYQ1"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['text'].tail(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsoCHf12dPhc",
        "outputId": "7b43389b-a4c8-4368-c4ab-755f41162638"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15739    lings \\t ivaru cinemala laam nalla tha prasura...\n",
              "15740    \\t Pattaya Kilaputhupaa trailer... !!!!! Get R...\n",
              "15741    lings \\t En innum trending la varala? Ennada p...\n",
              "15742        \\t Rajnikant sir plz aap india ke pm ban jaao\n",
              "15743    lings \\t Enagada YouTube inum trending la add ...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_categories = 5\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['category'], test_size=0.2, random_state=42)\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.transform(y_test)\n",
        "\n",
        "max_len = 100\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=num_categories)\n",
        "y_test_cat = to_categorical(y_test, num_classes=num_categories)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=32, input_length=max_len))\n",
        "model.add(LSTM(units=64, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(units=num_categories, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJJvwyIzdOqU",
        "outputId": "73a28230-aa64-4323-8003-88f18dcaa454"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "model.fit(X_train_pad, y_train_cat, epochs=10, batch_size=32, validation_data=(X_test_pad, y_test_cat), callbacks=[early_stopping])\n",
        "model.save('tanglish_sentiment_lstm.h5')\n",
        "loss, accuracy = model.evaluate(X_test_pad, y_test_cat, verbose=0)\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "J2h2JkySHAJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f425fc70-e423-4e31-a9fa-68b8b5a8537f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "394/394 [==============================] - 186s 451ms/step - loss: 0.7923 - accuracy: 0.7350 - val_loss: 0.4733 - val_accuracy: 0.8250\n",
            "Epoch 2/10\n",
            "394/394 [==============================] - 166s 421ms/step - loss: 0.3612 - accuracy: 0.8638 - val_loss: 0.4190 - val_accuracy: 0.8269\n",
            "Epoch 3/10\n",
            "394/394 [==============================] - 166s 422ms/step - loss: 0.2981 - accuracy: 0.8888 - val_loss: 0.4135 - val_accuracy: 0.8453\n",
            "Epoch 4/10\n",
            "394/394 [==============================] - 168s 427ms/step - loss: 0.2553 - accuracy: 0.9073 - val_loss: 0.4283 - val_accuracy: 0.8399\n",
            "Epoch 5/10\n",
            "394/394 [==============================] - 164s 416ms/step - loss: 0.2187 - accuracy: 0.9205 - val_loss: 0.4562 - val_accuracy: 0.8358\n",
            "Epoch 6/10\n",
            "394/394 [==============================] - 166s 419ms/step - loss: 0.1931 - accuracy: 0.9298 - val_loss: 0.4784 - val_accuracy: 0.8323\n",
            "Accuracy: 0.8323277235031128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('tanglish_sentiment_lstm.h5')\n",
        "\n",
        "test_text = ['padam nalla iruke']\n",
        "test_seq = tokenizer.texts_to_sequences(test_text)\n",
        "test_pad = pad_sequences(test_seq, maxlen=max_len)\n",
        "pred = model.predict(test_pad)\n",
        "\n",
        "for p in pred:\n",
        "    print(np.argmax(p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nrVx1I0K4z4",
        "outputId": "15729dae-eb8a-4c37-8b24-337d85d9f4ff"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 324ms/step\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_category = encoder.inverse_transform([np.argmax(pred)])\n",
        "print(predicted_category)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqUXkU16N7Ko",
        "outputId": "d7fbfef9-9abf-46e6-9ec1-b2dee846a2f5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Positive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using CountVectorizer for word embedding"
      ],
      "metadata": {
        "id": "MtR7t3g4gGti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils  import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "data = pd.read_csv('/content/Tamil_sentiments.csv', encoding='utf-8')\n",
        "\n",
        "num_categories = 5\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['category'], test_size=0.2, random_state=42)\n",
        "\n",
        "vectorizer = CountVectorizer(max_features=5000)\n",
        "\n",
        "X_train_seq = vectorizer.fit_transform(X_train).toarray()\n",
        "X_test_seq = vectorizer.transform(X_test).toarray()\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.transform(y_test)\n",
        "\n",
        "max_len = 100\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=num_categories)\n",
        "y_test_cat = to_categorical(y_test, num_classes=num_categories)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=32, input_length=max_len))\n",
        "model.add(LSTM(units=64, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(units=num_categories, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keQ01n-0QHif",
        "outputId": "ff694a3e-80ca-4982-f420-6baf7be7b0ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "model.fit(X_train_pad, y_train_cat, epochs=10, batch_size=32, validation_data=(X_test_pad, y_test_cat), callbacks=[early_stopping])\n",
        "\n",
        "model.save('tanglish_sentiment_lstm_countvectorizer.h5')\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_pad, y_test_cat, verbose=0)\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOgTPniBQNgR",
        "outputId": "ef47c620-4d27-4f11-9a8e-bcde2c76a266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "394/394 [==============================] - 178s 445ms/step - loss: 1.0562 - accuracy: 0.6731 - val_loss: 1.0839 - val_accuracy: 0.6548\n",
            "Epoch 2/10\n",
            "394/394 [==============================] - 175s 445ms/step - loss: 1.0428 - accuracy: 0.6746 - val_loss: 1.0815 - val_accuracy: 0.6548\n",
            "Epoch 3/10\n",
            "394/394 [==============================] - 174s 441ms/step - loss: 1.0417 - accuracy: 0.6746 - val_loss: 1.0806 - val_accuracy: 0.6548\n",
            "Epoch 4/10\n",
            "394/394 [==============================] - 174s 441ms/step - loss: 1.0408 - accuracy: 0.6746 - val_loss: 1.0845 - val_accuracy: 0.6548\n",
            "Epoch 5/10\n",
            "394/394 [==============================] - 173s 438ms/step - loss: 1.0405 - accuracy: 0.6746 - val_loss: 1.0805 - val_accuracy: 0.6548\n",
            "Epoch 6/10\n",
            "394/394 [==============================] - 167s 424ms/step - loss: 1.0396 - accuracy: 0.6746 - val_loss: 1.0812 - val_accuracy: 0.6545\n",
            "Epoch 7/10\n",
            "394/394 [==============================] - 167s 424ms/step - loss: 1.0394 - accuracy: 0.6748 - val_loss: 1.0827 - val_accuracy: 0.6558\n",
            "Epoch 8/10\n",
            "394/394 [==============================] - 167s 424ms/step - loss: 1.0379 - accuracy: 0.6753 - val_loss: 1.0800 - val_accuracy: 0.6558\n",
            "Epoch 9/10\n",
            "394/394 [==============================] - 170s 432ms/step - loss: 1.0358 - accuracy: 0.6759 - val_loss: 1.0832 - val_accuracy: 0.6558\n",
            "Epoch 10/10\n",
            "394/394 [==============================] - 166s 422ms/step - loss: 1.0354 - accuracy: 0.6759 - val_loss: 1.0797 - val_accuracy: 0.6558\n",
            "Accuracy: 0.6557637453079224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('/content/tanglish_sentiment_lstm_countvectorizer.h5')\n",
        "\n",
        "test_text = [' நான் இன்னும் கூட உங்கள் புதிய படத்தை பார்க்க மிகவும் ஆசையாக இருக்கிறேன்']\n",
        "test_seq = tokenizer.texts_to_sequences(test_text)\n",
        "test_pad = pad_sequences(test_seq, maxlen=max_len)\n",
        "pred = model.predict(test_pad)\n",
        "\n",
        "for p in pred:\n",
        "    print(np.argmax(p))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h7ns-wgXpqI",
        "outputId": "1fb3a194-d403-4b03-9f51-995b5aca03a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 244ms/step\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_category = encoder.inverse_transform([np.argmax(pred)])\n",
        "print(predicted_category)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sL36X4DXxqO",
        "outputId": "3b3c1a79-a4b8-4411-9e26-f1323476094a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Positive']\n"
          ]
        }
      ]
    }
  ]
}